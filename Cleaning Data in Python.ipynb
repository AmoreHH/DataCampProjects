{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329f2690",
   "metadata": {},
   "source": [
    "### From: DataCamp course - Cleaning Data in Python\n",
    "### all the knowledge copy from Datacamp course that just save for learning and practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a1c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5355cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "ride_sharing = pd.read_csv('data/ride_sharing_new.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d8fb51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>station_A_id</th>\n",
       "      <th>station_A_name</th>\n",
       "      <th>station_B_id</th>\n",
       "      <th>station_B_name</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_birth_year</th>\n",
       "      <th>user_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 minutes</td>\n",
       "      <td>81</td>\n",
       "      <td>Berry St at 4th St</td>\n",
       "      <td>323</td>\n",
       "      <td>Broadway at Kearny</td>\n",
       "      <td>5480</td>\n",
       "      <td>2</td>\n",
       "      <td>1959</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24 minutes</td>\n",
       "      <td>3</td>\n",
       "      <td>Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>5193</td>\n",
       "      <td>2</td>\n",
       "      <td>1965</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 minutes</td>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>23</td>\n",
       "      <td>The Embarcadero at Steuart St</td>\n",
       "      <td>3652</td>\n",
       "      <td>3</td>\n",
       "      <td>1993</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 minutes</td>\n",
       "      <td>16</td>\n",
       "      <td>Steuart St at Market St</td>\n",
       "      <td>28</td>\n",
       "      <td>The Embarcadero at Bryant St</td>\n",
       "      <td>1883</td>\n",
       "      <td>1</td>\n",
       "      <td>1979</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 minutes</td>\n",
       "      <td>22</td>\n",
       "      <td>Howard St at Beale St</td>\n",
       "      <td>350</td>\n",
       "      <td>8th St at Brannan St</td>\n",
       "      <td>4626</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     duration  station_A_id  \\\n",
       "0  12 minutes            81   \n",
       "1  24 minutes             3   \n",
       "2   8 minutes            67   \n",
       "3   4 minutes            16   \n",
       "4  11 minutes            22   \n",
       "\n",
       "                                      station_A_name  station_B_id  \\\n",
       "0                                 Berry St at 4th St           323   \n",
       "1       Powell St BART Station (Market St at 4th St)           118   \n",
       "2  San Francisco Caltrain Station 2  (Townsend St...            23   \n",
       "3                            Steuart St at Market St            28   \n",
       "4                              Howard St at Beale St           350   \n",
       "\n",
       "                    station_B_name  bike_id  user_type  user_birth_year  \\\n",
       "0               Broadway at Kearny     5480          2             1959   \n",
       "1  Eureka Valley Recreation Center     5193          2             1965   \n",
       "2    The Embarcadero at Steuart St     3652          3             1993   \n",
       "3     The Embarcadero at Bryant St     1883          1             1979   \n",
       "4             8th St at Brannan St     4626          2             1994   \n",
       "\n",
       "  user_gender  \n",
       "0        Male  \n",
       "1        Male  \n",
       "2        Male  \n",
       "3        Male  \n",
       "4        Male  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d9bea",
   "metadata": {},
   "source": [
    "### Summing strings and concatenating numbers\n",
    "In the previous exercise, you were able to identify that category is the correct data type for user_type and convert it in order to extract relevant statistical summaries that shed light on the distribution of user_type.\n",
    "\n",
    "Another common data type problem is importing what should be numerical values as strings, as mathematical operations such as summing and multiplication lead to string concatenation, not numerical outputs.\n",
    "\n",
    "In this exercise, you'll be converting the string column duration to the type int. Before that however, you will need to make sure to strip \"minutes\" from the column in order to make sure pandas reads it as numerical. The pandas package has been imported as pd.\n",
    "\n",
    "+ Use the .strip() method to strip duration of \"minutes\" and store it in the duration_trim column.\n",
    "+ Convert duration_trim to int and store it in the duration_time column.\n",
    "+ Write an assert statement that checks if duration_time's data type is now an int.\n",
    "+ Print the average ride duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f24ea308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         duration duration_trim  duration_time\n",
      "0      12 minutes           12              12\n",
      "1      24 minutes           24              24\n",
      "2       8 minutes            8               8\n",
      "3       4 minutes            4               4\n",
      "4      11 minutes           11              11\n",
      "...           ...           ...            ...\n",
      "25755  11 minutes           11              11\n",
      "25756  10 minutes           10              10\n",
      "25757  14 minutes           14              14\n",
      "25758  14 minutes           14              14\n",
      "25759  29 minutes           29              29\n",
      "\n",
      "[25760 rows x 3 columns]\n",
      "11.389052795031056\n"
     ]
    }
   ],
   "source": [
    "# Strip duration of minutes\n",
    "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip('minutes')\n",
    "\n",
    "# Convert duration to integer\n",
    "ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')\n",
    "\n",
    "# Write an assert statement making sure of conversion\n",
    "assert ride_sharing['duration_time'].dtype == 'int'\n",
    "\n",
    "# Print formed columns and calculate average ride duration \n",
    "print(ride_sharing[['duration','duration_trim','duration_time']])\n",
    "print(ride_sharing['duration_time'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3b23c",
   "metadata": {},
   "source": [
    "## Data range constraints\n",
    "+ How to deal with out of range data?\n",
    "    - Dropping data\n",
    "    - Setting custom minimums and maximums\n",
    "    - Treat as missing and impute\n",
    "    - Setting custom value depending on business assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe53ea",
   "metadata": {},
   "source": [
    "## Tire size constraints\n",
    "In this lesson, you're going to build on top of the work you've been doing with the ride_sharing DataFrame. You'll be working with the tire_sizes column which contains data on each bike's tire size.\n",
    "\n",
    "Bicycle tire sizes could be either 26″, 27″ or 29″ and are here correctly stored as a categorical value. In an effort to cut maintenance costs, the ride sharing provider decided to set the maximum tire size to be 27″.\n",
    "\n",
    "In this exercise, you will make sure the tire_sizes column has the correct range by first converting it to an integer, then setting and testing the new upper limit of 27″ for tire sizes.\n",
    "\n",
    "+ Convert the tire_sizes column from category to 'int'.\n",
    "+ Use .loc[] to set all values of tire_sizes above 27 to 27.\n",
    "+ Reconvert back tire_sizes to 'category' from int.\n",
    "+ Print the description of the tire_sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a9545",
   "metadata": {},
   "source": [
    "### dataset doesnot have  ['tire_sizes'] for use \n",
    "\n",
    "\n",
    "```python \n",
    "# Convert tire_sizes to integer\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('int')\n",
    "\n",
    "# Set all values above 27 to 27\n",
    "ride_sharing.loc[ride_sharing['tire_sizes'] > 27, 'tire_sizes'] = 27\n",
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('category')\n",
    "\n",
    "# Print tire size description\n",
    "print(ride_sharing['tire_sizes'].describe())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f1f8390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25760 entries, 0 to 25759\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   duration         25760 non-null  object\n",
      " 1   station_A_id     25760 non-null  int64 \n",
      " 2   station_A_name   25760 non-null  object\n",
      " 3   station_B_id     25760 non-null  int64 \n",
      " 4   station_B_name   25760 non-null  object\n",
      " 5   bike_id          25760 non-null  int64 \n",
      " 6   user_type        25760 non-null  int64 \n",
      " 7   user_birth_year  25760 non-null  int64 \n",
      " 8   user_gender      25760 non-null  object\n",
      " 9   duration_trim    25760 non-null  object\n",
      " 10  duration_time    25760 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ride_sharing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b283fb1",
   "metadata": {},
   "source": [
    "## Back to the future\n",
    "A new update to the data pipeline feeding into the ride_sharing DataFrame has been updated to register each ride's date. This information is stored in the ride_date column of the type object, which represents strings in pandas.\n",
    "\n",
    "A bug was discovered which was relaying rides taken today as taken next year. To fix this, you will find all instances of the ride_date column that occur anytime in the future, and set the maximum possible value of this column to today's date. Before doing so, you would need to convert ride_date to a datetime object.\n",
    "\n",
    "The datetime package has been imported as dt, alongside all the packages you've been using till now.\n",
    "\n",
    "+ Convert ride_date to a datetime object and store it in ride_dt column using to_datetime().\n",
    "+ Create the variable today, which stores today's date by using the dt.date.today() function.\n",
    "+ For all instances of ride_dt in the future, set them to today's date.\n",
    "+ Print the maximum date in the ride_dt column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63065c",
   "metadata": {},
   "source": [
    "### dataset doesnot have  ['ride_date'] for use \n",
    "\n",
    "```python \n",
    "# Convert ride_date to datetime\n",
    "ride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_date'])\n",
    "\n",
    "# Save today's date\n",
    "today = dt.date.today()\n",
    "\n",
    "# Set all in the future to today's date\n",
    "ride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n",
    "\n",
    "# Print maximum of ride_dt column\n",
    "print(ride_sharing['ride_dt'].max())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cefc74",
   "metadata": {},
   "source": [
    "## Uniqueness constraints\n",
    "\n",
    "+ How to find duplicate values?\n",
    "  - Get duplicates across all columns\n",
    "```python \n",
    "duplicates = height_weight.duplicated()\n",
    "print(duplicates)\n",
    "```\n",
    "\n",
    "如果直接這樣做而不做任何設定的話，預設是要在所有欄位都相同的情況下才會被判為是重複值，\n",
    "但比較實務的作法是加上兩個指定的功能：\n",
    " - subset: 例出要比較的col name，也就是只要在這個/些 col上有重複值就列下；\n",
    " - keep：要保留的是哪一個重複值，是=first第一筆出現的還是=last最後一筆出現的，或是 =False全部保留 \n",
    "\n",
    "```python \n",
    "# column names to check for duplication\n",
    "column_names = ['first_name', 'last_name', 'address']\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep=False)\n",
    "``` \n",
    "也可以針對output內容進行排序\n",
    "```python\n",
    "height_weight[duplicates].sort_values(by='first_name')\n",
    "``` \n",
    "\n",
    "\n",
    "### 使用 drop_duplicates()把重複值自動丟棄\n",
    "\n",
    "除了上述的subset 與 keep之外，還有一個功能 **inplace** : 將重複的row直接丟棄而非新建一個object(True), 通常會使用 inplace=True的方法因為大多時候重複值是無用的\n",
    "\n",
    "但要注意，如果inplace= True時，keep不能等於 False, 因為這樣是矛盾的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df27ea",
   "metadata": {},
   "source": [
    "## Finding duplicates\n",
    "A new update to the data pipeline feeding into ride_sharing has added the ride_id column, which represents a unique identifier for each ride.\n",
    "\n",
    "The update however coincided with radically shorter average ride duration times and irregular user birth dates set in the future. Most importantly, the number of rides taken has increased by 20% overnight, leading you to think there might be both complete and incomplete duplicates in the ride_sharing DataFrame.\n",
    "\n",
    "In this exercise, you will confirm this suspicion by finding those duplicates. A sample of ride_sharing is in your environment, as well as all the packages you've been working with thus far.\n",
    "\n",
    "\n",
    "+ Find duplicated rows of ride_id in the ride_sharing DataFrame while setting keep to False.\n",
    "+ Subset ride_sharing on duplicates and sort by ride_id and assign the results to duplicated_rides.\n",
    "+ Print the ride_id, duration and user_birth_year columns of duplicated_rides in that order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa16418",
   "metadata": {},
   "source": [
    "### dataset doesnot have  ['ride_id'] for use \n",
    "\n",
    "```python \n",
    "# Find duplicates\n",
    "duplicates = ride_sharing.duplicated(subset ='ride_id', keep=False)\n",
    "\n",
    "# Sort your duplicated rides\n",
    "duplicated_rides = ride_sharing[duplicates].sort_values(by='ride_id')\n",
    "\n",
    "# Print relevant columns of duplicated_rides\n",
    "print(duplicated_rides[['ride_id','duration','user_birth_year']])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790d134",
   "metadata": {},
   "source": [
    "### Treating duplicates\n",
    "In the last exercise, you were able to verify that the new update feeding into ride_sharing contains a bug generating both complete and incomplete duplicated rows for some values of the ride_id column, with occasional discrepant values for the user_birth_year and duration columns.\n",
    "\n",
    "In this exercise, you will be treating those duplicated rows by first dropping complete duplicates, and then merging the incomplete duplicate rows into one while keeping the average duration, and the minimum user_birth_year for each set of incomplete duplicate rows.\n",
    "\n",
    "\n",
    "+ Drop complete duplicates in ride_sharing and store the results in ride_dup.\n",
    "+ Create the statistics dictionary which holds minimum aggregation for user_birth_year and mean aggregation for duration.\n",
    "+ Drop incomplete duplicates by grouping by ride_id and applying the aggregation in statistics.\n",
    "+ Find duplicates again and run the assert statement to verify de-duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43538b99",
   "metadata": {},
   "source": [
    "### dataset doesnot have  ['ride_id'] for use \n",
    "\n",
    "```python\n",
    "# Drop complete duplicates from ride_sharing\n",
    "ride_dup = ride_sharing.drop_duplicates()\n",
    "\n",
    "# Create statistics dictionary for aggregation function\n",
    "statistics = {'user_birth_year': 'min', 'duration': 'mean'}\n",
    "\n",
    "# Group by ride_id and compute new statistics\n",
    "ride_unique = ride_dup.groupby(by='ride_id').agg(statistics).reset_index()\n",
    "\n",
    "# Find duplicated values again\n",
    "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
    "duplicated_rides = ride_unique[duplicates == True]\n",
    "\n",
    "# Assert duplicates are processed\n",
    "assert duplicated_rides.shape[0] == 0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b1c4f",
   "metadata": {},
   "source": [
    "## Text and categorical data problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec7bc5",
   "metadata": {},
   "source": [
    "### Membership （）\n",
    "\n",
    "通常在category data上會發生的錯誤可能是源於 typo / free text、下拉選單（dropdown）或其他所造成，處理的方式通常為丟棄（dropping data）、重新對應分類（remapping categories）、或是推論其類別（inferring categories）\n",
    "\n",
    "首先，專注於 dropping data\n",
    "\n",
    "回顧一下 join, 這裡主要關注的是\n",
    "+ Anti Joins(What is in A and not in B) : how='left' or how='right'\n",
    "+ Inner Joins (What is both in A and B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3b811",
   "metadata": {},
   "source": [
    "## Finding consistency\n",
    "In this exercise and throughout this chapter, you'll be working with the airlines DataFrame which contains survey responses on the San Francisco Airport from airline customers.\n",
    "\n",
    "The DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction. Another DataFrame named categories was created, containing all correct possible values for the survey columns.\n",
    "\n",
    "In this exercise, you will use both of these DataFrames to find survey answers with inconsistent values, and drop them, effectively performing an outer and inner join on both these DataFrames as seen in the video exercise. The pandas package has been imported as pd, and the airlines and categories DataFrames are in your environment.\n",
    "\n",
    "\n",
    "+ Print the categories DataFrame and take a close look at all possible correct categories of the survey columns.\n",
    "+ Print the unique values of the survey columns in airlines using the .unique() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660f8264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        day      airline        destination    dest_region dest_size  \\\n",
       "0  1351    Tuesday  UNITED INTL             KANSAI           Asia       Hub   \n",
       "1   373     Friday       ALASKA  SAN JOSE DEL CABO  Canada/Mexico     Small   \n",
       "2  2820   Thursday        DELTA        LOS ANGELES        West US       Hub   \n",
       "3  1157    Tuesday    SOUTHWEST        LOS ANGELES        West US       Hub   \n",
       "4  2992  Wednesday     AMERICAN              MIAMI        East US       Hub   \n",
       "\n",
       "  boarding_area   dept_time  wait_min     cleanliness         safety  \\\n",
       "0  Gates 91-102  2018-12-31     115.0           Clean        Neutral   \n",
       "1   Gates 50-59  2018-12-31     135.0           Clean      Very safe   \n",
       "2   Gates 40-48  2018-12-31      70.0         Average  Somewhat safe   \n",
       "3   Gates 20-39  2018-12-31     190.0           Clean      Very safe   \n",
       "4   Gates 50-59  2018-12-31     559.0  Somewhat clean      Very safe   \n",
       "\n",
       "         satisfaction  \n",
       "0      Very satisfied  \n",
       "1      Very satisfied  \n",
       "2             Neutral  \n",
       "3  Somewhat satsified  \n",
       "4  Somewhat satsified  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "airlines = pd.read_csv('data/airlines_final.csv', index_col=0)\n",
    "airlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3fd4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanliness:  ['Clean' 'Average' 'Somewhat clean' 'Somewhat dirty' 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satsified' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca3224",
   "metadata": {},
   "source": [
    "## Inconsistent categories\n",
    "In this exercise, you'll be revisiting the airlines DataFrame from the previous lesson.\n",
    "\n",
    "As a reminder, the DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction on the San Francisco Airport.\n",
    "\n",
    "In this exercise, you will examine two categorical columns from this DataFrame, dest_region and dest_size respectively, assess how to address them and make sure that they are cleaned and ready for analysis. The pandas package has been imported as pd, and the airlines DataFrame is in your environment.\n",
    "\n",
    "+ Print the unique values in dest_region and dest_size respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad390caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east'] \n",
      "\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique(), \"\\n\")\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf556830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n"
     ]
    }
   ],
   "source": [
    "#The dest_region column has inconsistent values due to capitalization and has one value that needs to be remapped.\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "print(airlines['dest_region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f1ac8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "#The dest_size column has only inconsistent values due to leading and trailing spaces.\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_size'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20caa5ea",
   "metadata": {},
   "source": [
    "## Remapping categories\n",
    "To better understand survey respondents from airlines, you want to find out if there is a relationship between certain responses and the day of the week and wait time at the gate.\n",
    "\n",
    "The airlines DataFrame contains the day and wait_min columns, which are categorical and numerical respectively. The day column contains the exact day a flight took place, and wait_min contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:\n",
    "\n",
    "wait_type: 'short' for 0-60 min, 'medium' for 60-180 and long for 180+\n",
    "day_week: 'weekday' if day is in the weekday, 'weekend' if day is in the weekend.\n",
    "The pandas and numpy packages have been imported as pd and np. Let's create some new categorical data!\n",
    "\n",
    "+ Create the ranges and labels for the wait_type column mentioned in the description above.\n",
    "+ Create the wait_type column by from wait_min by using pd.cut(), while inputting label_ranges and label_names in the correct arguments.\n",
    "+ Create the mapping dictionary mapping weekdays to 'weekday' and weekend days to 'weekend'.\n",
    "+ Create the day_week column by using .replace()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "830bfd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      wait_min wait_type day_week\n",
      "0        115.0    medium  weekday\n",
      "1        135.0    medium  weekday\n",
      "2         70.0    medium  weekday\n",
      "3        190.0      long  weekday\n",
      "4        559.0      long  weekday\n",
      "...        ...       ...      ...\n",
      "2804     280.0      long  weekday\n",
      "2805     165.0    medium  weekday\n",
      "2806      92.0    medium  weekday\n",
      "2807      95.0    medium  weekday\n",
      "2808     220.0      long  weekend\n",
      "\n",
      "[2477 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)\n",
    "print(airlines[['wait_min','wait_type', 'day_week']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a021d64",
   "metadata": {},
   "source": [
    "## Removing titles and taking names\n",
    "While collecting survey respondent metadata in the airlines DataFrame, the full name of respondents was saved in the full_name column. However upon closer inspection, you found that a lot of the different names are prefixed by honorifics such as \"Dr.\", \"Mr.\", \"Ms.\" and \"Miss\".\n",
    "\n",
    "Your ultimate objective is to create two new columns named first_name and last_name, containing the first and last names of respondents respectively. Before doing so however, you need to remove honorifics.\n",
    "\n",
    "The airlines DataFrame is in your environment, alongside pandas as pd.\n",
    "\n",
    "\n",
    "+ Remove \"Dr.\", \"Mr.\", \"Miss\" and \"Ms.\" from full_name by replacing them with an empty string \"\" in that order.\n",
    "+ Run the assert statement using .str.contains() that tests whether full_name still contains any of the honorifics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c2f314",
   "metadata": {},
   "source": [
    "### dataset doesnot have  ['full_name'] for use \n",
    "\n",
    "```python\n",
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Dr.\",\"\")\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Mr.\",\"\")\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Miss\",\"\")\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace(\"Ms.\",\"\")\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms.|Mr.|Miss|Dr.').any() == False\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a47a31",
   "metadata": {},
   "source": [
    "## Keeping it descriptive\n",
    "To further understand travelers' experiences in the San Francisco Airport, the quality assurance department sent out a qualitative questionnaire to all travelers who gave the airport the worst score on all possible categories. The objective behind this questionnaire is to identify common patterns in what travelers are saying about the airport.\n",
    "\n",
    "Their response is stored in the survey_response column. Upon a closer look, you realized a few of the answers gave the shortest possible character amount without much substance. In this exercise, you will isolate the responses with a character count higher than 40 , and make sure your new DataFrame contains responses with 40 characters or more using an assert statement.\n",
    "\n",
    "The airlines DataFrame is in your environment, and pandas is imported as pd.\n",
    "\n",
    "因為低於40個字的回覆通常沒有太多參考價值，所以只想看反覆超過40個字的問卷就好\n",
    "\n",
    "+ Using the airlines DataFrame, store the length of each instance in the survey_response column in resp_length by using .str.len().\n",
    "+ Isolate the rows of airlines with resp_length higher than 40.\n",
    "+ Assert that the smallest survey_response length in airlines_survey is now bigger than 40."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa14d2",
   "metadata": {},
   "source": [
    "### dataset doesnot have  ['survey_response'] for use \n",
    "\n",
    "```python\n",
    "\n",
    "# Store length of each row in survey_response column\n",
    "resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey['survey_response'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610e2428",
   "metadata": {},
   "source": [
    "\n",
    "# Advanced data problems\n",
    "\n",
    "In this chapter, you’ll dive into more advanced data cleaning problems, such as ensuring that weights are all written in kilograms instead of pounds. \n",
    "\n",
    "You’ll also gain invaluable skills that will help you verify that values have been added correctly and that missing values don’t negatively impact your analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eb43cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>Age</th>\n",
       "      <th>acct_amount</th>\n",
       "      <th>inv_amount</th>\n",
       "      <th>fund_A</th>\n",
       "      <th>fund_B</th>\n",
       "      <th>fund_C</th>\n",
       "      <th>fund_D</th>\n",
       "      <th>account_opened</th>\n",
       "      <th>last_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>870A9281</td>\n",
       "      <td>1962-06-09</td>\n",
       "      <td>58</td>\n",
       "      <td>63523.31</td>\n",
       "      <td>51295</td>\n",
       "      <td>30105.0</td>\n",
       "      <td>4138.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>15632.0</td>\n",
       "      <td>02-09-18</td>\n",
       "      <td>22-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166B05B0</td>\n",
       "      <td>1962-12-16</td>\n",
       "      <td>58</td>\n",
       "      <td>38175.46</td>\n",
       "      <td>15050</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>6696.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>28-02-19</td>\n",
       "      <td>31-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFC13E88</td>\n",
       "      <td>1990-09-12</td>\n",
       "      <td>34</td>\n",
       "      <td>59863.77</td>\n",
       "      <td>24567</td>\n",
       "      <td>10323.0</td>\n",
       "      <td>4590.0</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>25-04-18</td>\n",
       "      <td>02-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F2158F66</td>\n",
       "      <td>1985-11-03</td>\n",
       "      <td>35</td>\n",
       "      <td>84132.10</td>\n",
       "      <td>23712</td>\n",
       "      <td>3908.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>6482.0</td>\n",
       "      <td>12830.0</td>\n",
       "      <td>07-11-17</td>\n",
       "      <td>08-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7A73F334</td>\n",
       "      <td>1990-05-17</td>\n",
       "      <td>30</td>\n",
       "      <td>120512.00</td>\n",
       "      <td>93230</td>\n",
       "      <td>12158.4</td>\n",
       "      <td>51281.0</td>\n",
       "      <td>13434.0</td>\n",
       "      <td>18383.0</td>\n",
       "      <td>14-05-18</td>\n",
       "      <td>19-07-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cust_id  birth_date  Age  acct_amount  inv_amount   fund_A   fund_B  \\\n",
       "0  870A9281  1962-06-09   58     63523.31       51295  30105.0   4138.0   \n",
       "1  166B05B0  1962-12-16   58     38175.46       15050   4995.0    938.0   \n",
       "2  BFC13E88  1990-09-12   34     59863.77       24567  10323.0   4590.0   \n",
       "3  F2158F66  1985-11-03   35     84132.10       23712   3908.0    492.0   \n",
       "4  7A73F334  1990-05-17   30    120512.00       93230  12158.4  51281.0   \n",
       "\n",
       "    fund_C   fund_D account_opened last_transaction  \n",
       "0   1420.0  15632.0       02-09-18         22-02-19  \n",
       "1   6696.0   2421.0       28-02-19         31-10-18  \n",
       "2   8469.0   1185.0       25-04-18         02-04-18  \n",
       "3   6482.0  12830.0       07-11-17         08-11-18  \n",
       "4  13434.0  18383.0       14-05-18         19-07-18  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "banking = pd.read_csv('data/banking_dirty.csv', index_col=0)\n",
    "banking.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0b4a7",
   "metadata": {},
   "source": [
    "## Uniform currencies\n",
    "In this exercise and throughout this chapter, you will be working with a retail banking dataset stored in the banking DataFrame. The dataset contains data on the amount of money stored in accounts (acct_amount), their currency (acct_cur), amount invested (inv_amount), account opening date (account_opened), and last transaction date (last_transaction) that were consolidated from American and European branches.\n",
    "\n",
    "You are tasked with understanding the average account size and how investments vary by the size of account, however in order to produce this analysis accurately, you first need to unify the currency amount into dollars. The pandas package has been imported as pd, and the banking DataFrame is in your environment.\n",
    "\n",
    "+ Find the rows of acct_cur in banking that are equal to 'euro' and store them in the variable acct_eu.\n",
    "+ Find all the rows of acct_amount in banking that fit the acct_eu condition, and convert them to USD by multiplying them with 1.1.\n",
    "+ Find all the rows of acct_cur in banking that fit the acct_eu condition, set them to 'dollar'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e028c",
   "metadata": {},
   "source": [
    "### dataset doesnot have  ['acct_cur'] for use \n",
    "\n",
    "```python\n",
    "# Find values of acct_cur that are equal to 'euro'\n",
    "acct_eu = banking['acct_cur'] == 'euro'\n",
    "\n",
    "# Convert acct_amount where it is in euro to dollars\n",
    "banking.loc[acct_eu, 'acct_amount'] = banking.loc[acct_eu, 'acct_amount'] * 1.1\n",
    "# Unify acct_cur column by changing 'euro' values to 'dollar'\n",
    "banking.loc[acct_eu, 'acct_cur'] = 'dollar'\n",
    "\n",
    "# Assert that only dollar currency remains\n",
    "assert banking['acct_cur'].unique() == 'dollar'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fd63c5",
   "metadata": {},
   "source": [
    "## Uniform dates\n",
    "After having unified the currencies of your different account amounts, you want to add a temporal dimension to your analysis and see how customers have been investing their money given the size of their account over each year. The account_opened column represents when customers opened their accounts and is a good proxy for segmenting customer activity and investment over time.\n",
    "\n",
    "However, since this data was consolidated from multiple sources, you need to make sure that all dates are of the same format. You will do so by converting this column into a datetime object, while making sure that the format is inferred and potentially incorrect formats are set to missing. The banking DataFrame is in your environment and pandas was imported as pd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60cf5cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    02-09-18\n",
      "1    28-02-19\n",
      "2    25-04-18\n",
      "3    07-11-17\n",
      "4    14-05-18\n",
      "Name: account_opened, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the header of account_opened from the banking DataFrame and take a look at the different results.\n",
    "print(banking['account_opened'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2a255",
   "metadata": {},
   "source": [
    "## Cross field validation\n",
    "使用資料集中的多個字串來驗證資料的正確性\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96329da4",
   "metadata": {},
   "source": [
    "## How's our data integrity?\n",
    "New data has been merged into the banking DataFrame that contains details on how investments in the inv_amount column are allocated across four different funds A, B, C and D. \n",
    "\n",
    "     **將來自4個founder的資金加總，用來檢查 inv_amount 這欄有沒有錯誤**\n",
    "\n",
    "Furthermore, the age and birthdays of customers are now stored in the age and birth_date columns respectively.\n",
    "   \n",
    "       **由生日來檢查 age 這欄有沒有錯誤**\n",
    "\n",
    "You want to understand how customers of different age groups invest. However, you want to first make sure the data you're analyzing is correct. You will do so by cross field checking values of inv_amount and age against the amount invested in different funds and customers' birthdays. Both pandas and datetime have been imported as pd and dt respectively.\n",
    "\n",
    "+ Find the rows where the sum of all rows of the fund_columns in banking are equal to the inv_amount column.\n",
    "+ Store the values of banking with consistent inv_amount in consistent_inv, and those with inconsistent ones in inconsistent_inv.\n",
    "\n",
    "\n",
    "+ Store today's date into today, and manually calculate customers' ages and store them in ages_manual.\n",
    "+ Find all rows of banking where the age column is equal to ages_manual and then filter banking into consistent_ages and inconsistent_ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7277e837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>Age</th>\n",
       "      <th>acct_amount</th>\n",
       "      <th>inv_amount</th>\n",
       "      <th>fund_A</th>\n",
       "      <th>fund_B</th>\n",
       "      <th>fund_C</th>\n",
       "      <th>fund_D</th>\n",
       "      <th>account_opened</th>\n",
       "      <th>last_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>870A9281</td>\n",
       "      <td>1962-06-09</td>\n",
       "      <td>58</td>\n",
       "      <td>63523.31</td>\n",
       "      <td>51295</td>\n",
       "      <td>30105.0</td>\n",
       "      <td>4138.0</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>15632.0</td>\n",
       "      <td>02-09-18</td>\n",
       "      <td>22-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166B05B0</td>\n",
       "      <td>1962-12-16</td>\n",
       "      <td>58</td>\n",
       "      <td>38175.46</td>\n",
       "      <td>15050</td>\n",
       "      <td>4995.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>6696.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>28-02-19</td>\n",
       "      <td>31-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFC13E88</td>\n",
       "      <td>1990-09-12</td>\n",
       "      <td>34</td>\n",
       "      <td>59863.77</td>\n",
       "      <td>24567</td>\n",
       "      <td>10323.0</td>\n",
       "      <td>4590.0</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>25-04-18</td>\n",
       "      <td>02-04-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F2158F66</td>\n",
       "      <td>1985-11-03</td>\n",
       "      <td>35</td>\n",
       "      <td>84132.10</td>\n",
       "      <td>23712</td>\n",
       "      <td>3908.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>6482.0</td>\n",
       "      <td>12830.0</td>\n",
       "      <td>07-11-17</td>\n",
       "      <td>08-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7A73F334</td>\n",
       "      <td>1990-05-17</td>\n",
       "      <td>30</td>\n",
       "      <td>120512.00</td>\n",
       "      <td>93230</td>\n",
       "      <td>12158.4</td>\n",
       "      <td>51281.0</td>\n",
       "      <td>13434.0</td>\n",
       "      <td>18383.0</td>\n",
       "      <td>14-05-18</td>\n",
       "      <td>19-07-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cust_id  birth_date  Age  acct_amount  inv_amount   fund_A   fund_B  \\\n",
       "0  870A9281  1962-06-09   58     63523.31       51295  30105.0   4138.0   \n",
       "1  166B05B0  1962-12-16   58     38175.46       15050   4995.0    938.0   \n",
       "2  BFC13E88  1990-09-12   34     59863.77       24567  10323.0   4590.0   \n",
       "3  F2158F66  1985-11-03   35     84132.10       23712   3908.0    492.0   \n",
       "4  7A73F334  1990-05-17   30    120512.00       93230  12158.4  51281.0   \n",
       "\n",
       "    fund_C   fund_D account_opened last_transaction  \n",
       "0   1420.0  15632.0       02-09-18         22-02-19  \n",
       "1   6696.0   2421.0       28-02-19         31-10-18  \n",
       "2   8469.0   1185.0       25-04-18         02-04-18  \n",
       "3   6482.0  12830.0       07-11-17         08-11-18  \n",
       "4  13434.0  18383.0       14-05-18         19-07-18  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3da3de51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent investments:  8\n"
     ]
    }
   ],
   "source": [
    "# Store fund columns to sum against\n",
    "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']\n",
    "\n",
    "# Find rows where fund_columns row sum == inv_amount\n",
    "inv_equ = banking[fund_columns].sum(axis=1) == banking['inv_amount']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_inv = banking[inv_equ]\n",
    "inconsistent_inv = banking[~inv_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7d830e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent ages:  100\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "banking['birth_date'] = pd.to_datetime(banking['birth_date'])\n",
    "\n",
    "# Store today's date and find ages\n",
    "today = dt.date.today()\n",
    "ages_manual = today.year - banking['birth_date'].dt.year\n",
    "\n",
    "# Find rows where age column == ages_manual\n",
    "age_equ = ages_manual == banking['Age']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_ages = banking[age_equ]\n",
    "inconsistent_ages = banking[~age_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent ages: \", inconsistent_ages.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78696e53",
   "metadata": {},
   "source": [
    "# Completness and Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9e5c5",
   "metadata": {},
   "source": [
    "## Missing investors\n",
    "Dealing with missing data is one of the most common tasks in data science. There are a variety of types of missingness, as well as a variety of types of solutions to missing data.\n",
    "\n",
    "You just received a new version of the banking DataFrame containing data on the amount held and invested for new and existing customers. However, there are rows with missing inv_amount values.\n",
    "\n",
    "You know for a fact that most customers below 25 do not have investment accounts yet, and suspect it could be driving the missingness. The pandas, missingno and matplotlib.pyplot packages have been imported as pd, msno and plt respectively. The banking DataFrame is in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "716fc282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cust_id             0\n",
      "birth_date          0\n",
      "Age                 0\n",
      "acct_amount         0\n",
      "inv_amount          0\n",
      "fund_A              0\n",
      "fund_B              0\n",
      "fund_C              0\n",
      "fund_D              0\n",
      "account_opened      0\n",
      "last_transaction    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the number of missing values by column in the banking DataFrame.\n",
    "# Print number of missing values in banking\n",
    "print(banking.isna().sum())\n",
    "\n",
    "\n",
    "# Plot and show the missingness matrix of banking with the msno.matrix() function.\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Visualize missingness matrix\n",
    "msno.matrix(banking)\n",
    "plt.show()\n",
    "#這個資料集和課程的不一樣，這裡沒有 missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50e39ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate the values of banking missing values of inv_amount into missing_investors \n",
    "#and with non-missing inv_amount values into investors.\n",
    "\n",
    "# Isolate missing and non missing values of inv_amount\n",
    "missing_investors = banking[banking['inv_amount'].isna()]\n",
    "investors = banking[~banking['inv_amount'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd03804",
   "metadata": {},
   "source": [
    "## Follow the money\n",
    "In this exercise, you're working with another version of the banking DataFrame that contains missing values for both the cust_id column and the acct_amount column.\n",
    "\n",
    "You want to produce analysis on how many unique customers the bank has, the average amount held by customers and more. You know that rows with missing cust_id don't really help you, and that on average acct_amount is usually 5 times the amount of inv_amount.\n",
    "\n",
    "In this exercise, you will drop rows of banking with missing cust_ids, and impute missing values of acct_amount with some domain knowledge.\n",
    " \n",
    " \n",
    "+ Use .dropna() to drop missing values of the cust_id column in banking and store the results in banking_fullid.\n",
    "+ Use inv_amount to compute the estimated account amounts for banking_fullid by setting the amounts equal to inv_amount * 5, and assign the results to acct_imp.\n",
    "+ Impute the missing values of acct_amount in banking_fullid with the newly created acct_imp using .fillna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66b243ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cust_id             0\n",
      "birth_date          0\n",
      "Age                 0\n",
      "acct_amount         0\n",
      "inv_amount          0\n",
      "fund_A              0\n",
      "fund_B              0\n",
      "fund_C              0\n",
      "fund_D              0\n",
      "account_opened      0\n",
      "last_transaction    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop missing values of cust_id\n",
    "banking_fullid = banking.dropna(subset = ['cust_id'])\n",
    "\n",
    "# Compute estimated acct_amount\n",
    "acct_imp = banking_fullid['inv_amount']*5\n",
    "\n",
    "# Impute missing acct_amount with corresponding acct_imp\n",
    "banking_imputed = banking_fullid.fillna({'acct_amount':acct_imp})\n",
    "\n",
    "# Print number of missing values\n",
    "print(banking_imputed.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a309a5",
   "metadata": {},
   "source": [
    "# Record linkage\n",
    "\n",
    "Record linkage is a powerful technique used to merge multiple datasets together, used when values have typos or different spellings. In this chapter, you'll learn how to link records by calculating the similarity between strings—you’ll then use your new skills to join two restaurant review datasets into one clean master dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2906d3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "fuzz.WRatio('Reeding', 'Reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa5141bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Partial string comparison\n",
    "fuzz.WRatio('Houston Rockets', 'Rockets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15bdc99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Partial string comparison with different order\n",
    "fuzz.WRatio('Houston Rockets vs Los Angeles Lakers', 'Lakers vs Rockets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abfabf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.WRatio('Houston Rockets vs Los Angeles Lakers', 'Rockets vs Lakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56b9d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rockets vs Lakers', 86, 0), ('Lakers vs Rockets', 86, 1)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import process\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "#Define string and array of possible matches\n",
    "string = 'Houston Rockets vs Los Angeles Lakers'\n",
    "choices = pd.Series(['Rockets vs Lakers', 'Lakers vs Rockets', 'Houson vs Los Angeles', 'Heat vs Bulls'])\n",
    "\n",
    "process.extract(string, choices, limit=2)\n",
    "\n",
    "#第一個是相符的字串，第二個是相似性得分，第三個是在數列中位置的索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa156d6",
   "metadata": {},
   "source": [
    "## The cutoff point\n",
    "In this exercise, and throughout this chapter, you'll be working with the restaurants DataFrame which has data on various restaurants. Your ultimate goal is to create a restaurant recommendation engine, but you need to first clean your data.\n",
    "\n",
    "This version of restaurants has been collected from many sources, where the cuisine_type column is riddled with typos, and should contain only italian, american and asian cuisine types. There are so many unique categories that remapping them manually isn't scalable, and it's best to use string similarity instead.\n",
    "\n",
    "Before doing so, you want to establish the cutoff point for the similarity score using the fuzzywuzzy's process.extract() function by finding the similarity score of the most distant typo of each category.\n",
    "\n",
    "\n",
    "+ Import process from fuzzywuzzy.\n",
    "+ Store the unique cuisine_types into unique_types.\n",
    "+ Calculate the similarity of 'asian', 'american', and 'italian' to all possible cuisine_types using process.extract(), while returning all possible matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ceb5e106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kokomo</td>\n",
       "      <td>6333 w. third st.</td>\n",
       "      <td>la</td>\n",
       "      <td>2139330773</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feenix</td>\n",
       "      <td>8358 sunset blvd. west</td>\n",
       "      <td>hollywood</td>\n",
       "      <td>2138486677</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parkway</td>\n",
       "      <td>510 s. arroyo pkwy .</td>\n",
       "      <td>pasadena</td>\n",
       "      <td>8187951001</td>\n",
       "      <td>californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r-23</td>\n",
       "      <td>923 e. third st.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>2136877178</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gumbo</td>\n",
       "      <td>6333 w. third st.</td>\n",
       "      <td>la</td>\n",
       "      <td>2139330358</td>\n",
       "      <td>cajun/creole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                      addr         city       phone          type\n",
       "0   kokomo         6333 w. third st.           la  2139330773      american\n",
       "1   feenix   8358 sunset blvd. west     hollywood  2138486677      american\n",
       "2  parkway      510 s. arroyo pkwy .     pasadena  8187951001   californian\n",
       "3     r-23          923 e. third st.  los angeles  2136877178      japanese\n",
       "4    gumbo         6333 w. third st.           la  2139330358  cajun/creole"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "restaurants_dirty = pd.read_csv('data/restaurants_L2_dirty.csv', index_col=0)\n",
    "restaurants_dirty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f58c0778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>435 s. la cienega blv .</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>3102461501</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>art's delicatessen</td>\n",
       "      <td>12224 ventura blvd.</td>\n",
       "      <td>studio city</td>\n",
       "      <td>8187621221</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>campanile</td>\n",
       "      <td>624 s. la brea ave.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>2139381447</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fenix</td>\n",
       "      <td>8358 sunset blvd. west</td>\n",
       "      <td>hollywood</td>\n",
       "      <td>2138486677</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grill on the alley</td>\n",
       "      <td>9560 dayton way</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>3102760615</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name                       addr         city  \\\n",
       "0  arnie morton's of chicago   435 s. la cienega blv .   los angeles   \n",
       "1         art's delicatessen       12224 ventura blvd.   studio city   \n",
       "2                  campanile       624 s. la brea ave.   los angeles   \n",
       "3                      fenix    8358 sunset blvd. west     hollywood   \n",
       "4         grill on the alley           9560 dayton way   los angeles   \n",
       "\n",
       "        phone      type  \n",
       "0  3102461501  american  \n",
       "1  8187621221  american  \n",
       "2  2139381447  american  \n",
       "3  2138486677  american  \n",
       "4  3102760615  american  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants = pd.read_csv('data/restaurants_L2.csv', index_col=0)\n",
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217707f3",
   "metadata": {},
   "source": [
    "\n",
    "### dataset doesnot have  ['cuisine_type'] for use \n",
    "\n",
    "```python\n",
    "# Import process from fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Store the unique values of cuisine_type in unique_types\n",
    "unique_types = restaurants['cuisine_type'].unique()\n",
    "\n",
    "# Calculate similarity of 'asian' to all values of unique_types\n",
    "print(process.extract('asian', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'american' to all values of unique_types\n",
    "print(process.extract('american', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'italian' to all values of unique_types\n",
    "print(process.extract('italian', unique_types, limit = len(unique_types)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e6d55",
   "metadata": {},
   "source": [
    "# Generating pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90fe674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import recordlinkage\n",
    "# create indexing object 創建索引對象\n",
    "indexer = recordlinkage.Index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e0ee0",
   "metadata": {},
   "source": [
    "```python\n",
    "# Generate pairs blocked on state\n",
    "indexer.block('state')\n",
    "pairs=indexer.index(dfA, dfB)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54ebae2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kokomo</td>\n",
       "      <td>6333 w. third st.</td>\n",
       "      <td>la</td>\n",
       "      <td>2139330773</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feenix</td>\n",
       "      <td>8358 sunset blvd. west</td>\n",
       "      <td>hollywood</td>\n",
       "      <td>2138486677</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parkway</td>\n",
       "      <td>510 s. arroyo pkwy .</td>\n",
       "      <td>pasadena</td>\n",
       "      <td>8187951001</td>\n",
       "      <td>californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r-23</td>\n",
       "      <td>923 e. third st.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>2136877178</td>\n",
       "      <td>japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gumbo</td>\n",
       "      <td>6333 w. third st.</td>\n",
       "      <td>la</td>\n",
       "      <td>2139330358</td>\n",
       "      <td>cajun/creole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                      addr         city       phone          type\n",
       "0   kokomo         6333 w. third st.           la  2139330773      american\n",
       "1   feenix   8358 sunset blvd. west     hollywood  2138486677      american\n",
       "2  parkway      510 s. arroyo pkwy .     pasadena  8187951001   californian\n",
       "3     r-23          923 e. third st.  los angeles  2136877178      japanese\n",
       "4    gumbo         6333 w. third st.           la  2139330358  cajun/creole"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "restaurants_new = pd.read_csv('data/restaurants_L2_dirty.csv', index_col=0)\n",
    "restaurants_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985c232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>435 s. la cienega blv .</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>3102461501</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>art's delicatessen</td>\n",
       "      <td>12224 ventura blvd.</td>\n",
       "      <td>studio city</td>\n",
       "      <td>8187621221</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>campanile</td>\n",
       "      <td>624 s. la brea ave.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>2139381447</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fenix</td>\n",
       "      <td>8358 sunset blvd. west</td>\n",
       "      <td>hollywood</td>\n",
       "      <td>2138486677</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grill on the alley</td>\n",
       "      <td>9560 dayton way</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>3102760615</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name                       addr         city  \\\n",
       "0  arnie morton's of chicago   435 s. la cienega blv .   los angeles   \n",
       "1         art's delicatessen       12224 ventura blvd.   studio city   \n",
       "2                  campanile       624 s. la brea ave.   los angeles   \n",
       "3                      fenix    8358 sunset blvd. west     hollywood   \n",
       "4         grill on the alley           9560 dayton way   los angeles   \n",
       "\n",
       "        phone      type  \n",
       "0  3102461501  american  \n",
       "1  8187621221  american  \n",
       "2  2139381447  american  \n",
       "3  2138486677  american  \n",
       "4  3102760615  american  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants = pd.read_csv('data/restaurants_L2.csv', index_col=0)\n",
    "restaurants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d22da9",
   "metadata": {},
   "source": [
    "## Pairs of restaurants\n",
    "In the last lesson, you cleaned the restaurants dataset to make it ready for building a restaurants recommendation engine. You have a new DataFrame named restaurants_new with new restaurants to train your model on, that's been scraped from a new data source.\n",
    "\n",
    "You've already cleaned the cuisine_type and city columns using the techniques learned throughout the course. However you saw duplicates with typos in restaurants names that require record linkage instead of joins with restaurants.\n",
    "\n",
    "In this exercise, you will perform the first step in record linkage and generate possible pairs of rows between restaurants and restaurants_new. Both DataFrames, pandas and recordlinkage are in your environment.\n",
    "\n",
    "+ Instantiate an indexing object by using the Index() function from recordlinkage.\n",
    "+ Block your pairing on cuisine_type by using indexer's' .block() method.\n",
    "+ Generate pairs by indexing restaurants and restaurants_new in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69204cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexer and object and find possible pairs\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Block pairing on cuisine_type\n",
    "indexer.block('type')\n",
    "\n",
    "# Generate pairs\n",
    "pairs = indexer.index(restaurants, restaurants_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a51876",
   "metadata": {},
   "source": [
    "## Similar restaurants\n",
    "In the last exercise, you generated pairs between restaurants and restaurants_new in an effort to cleanly merge both DataFrames using record linkage.\n",
    "\n",
    "When performing record linkage, there are different types of matching you can perform between different columns of your DataFrames, including exact matches, string similarities, and more.\n",
    "\n",
    "Now that your pairs have been generated and stored in pairs, you will find exact matches in the city and cuisine_type columns between each pair, and similar strings for each pair in the rest_name column. Both DataFrames, pandas and recordlinkage are in your environment.\n",
    "+ Instantiate a comparison object using the recordlinkage.Compare() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44e03354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112550d",
   "metadata": {},
   "source": [
    "+ Use the appropriate comp_cl method to find exact matches between the city and cuisine_type columns of both DataFrames.\n",
    "+ Use the appropriate comp_cl method to find similar strings with a 0.8 similarity threshold in the rest_name column of both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89506957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compare>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find exact matches on city, cuisine_types - \n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('type', 'type', label='type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('name', 'name', label='name', threshold = 0.8) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3704c",
   "metadata": {},
   "source": [
    "+ Compute the comparison of the pairs by using the .compute() method of comp_cl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ccbe6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        city  type  name\n",
      "0   0      0     1   0.0\n",
      "    1      0     1   0.0\n",
      "    7      0     1   0.0\n",
      "    12     0     1   0.0\n",
      "    13     0     1   0.0\n",
      "...      ...   ...   ...\n",
      "40  18     0     1   0.0\n",
      "281 18     0     1   0.0\n",
      "288 18     0     1   0.0\n",
      "302 18     0     1   0.0\n",
      "308 18     0     1   0.0\n",
      "\n",
      "[3631 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get potential matches and print\n",
    "potential_matches = comp_cl.compute(pairs, restaurants, restaurants_new)\n",
    "print(potential_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146216a3",
   "metadata": {},
   "source": [
    "## Linking them together!\n",
    "In the last lesson, you've finished the bulk of the work on your effort to link restaurants and restaurants_new. You've generated the different pairs of potentially matching rows, searched for exact matches between the cuisine_type and city columns, but compared for similar strings in the rest_name column. You stored the DataFrame containing the scores in potential_matches.\n",
    "\n",
    "Now it's finally time to link both DataFrames. You will do so by first extracting all row indices of restaurants_new that are matching across the columns mentioned above from potential_matches. Then you will subset restaurants_new on these indices, then append the non-duplicate values to restaurants. All DataFrames are in your environment, alongside pandas imported as pd.\n",
    "\n",
    "\n",
    "+ Isolate instances of potential_matches where the row sum is above or equal to 3 by using the .sum() method.\n",
    "+ Extract the second column index from matches, which represents row indices of matching record from restaurants_new by using the .get_level_values() method.\n",
    "+ Subset restaurants_new for rows that are not in matching_indices.\n",
    "+ Append non_dup to restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19338b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name                       addr               city  \\\n",
      "0   arnie morton's of chicago   435 s. la cienega blv .         los angeles   \n",
      "1          art's delicatessen       12224 ventura blvd.         studio city   \n",
      "2                   campanile       624 s. la brea ave.         los angeles   \n",
      "3                       fenix    8358 sunset blvd. west           hollywood   \n",
      "4          grill on the alley           9560 dayton way         los angeles   \n",
      "..                        ...                        ...                ...   \n",
      "76                        don        1136 westwood blvd.           westwood   \n",
      "77                      feast        1949 westwood blvd.            west la   \n",
      "78                   mulberry        17040 ventura blvd.             encino   \n",
      "80                    jiraffe      502 santa monica blvd       santa monica   \n",
      "81                   martha's  22nd street grill 25 22nd  st. hermosa beach   \n",
      "\n",
      "         phone         type  \n",
      "0   3102461501     american  \n",
      "1   8187621221     american  \n",
      "2   2139381447     american  \n",
      "3   2138486677     american  \n",
      "4   3102760615     american  \n",
      "..         ...          ...  \n",
      "76  3102091422      italian  \n",
      "77  3104750400      chinese  \n",
      "78  8189068881        pizza  \n",
      "80  3109176671  californian  \n",
      "81  3103767786     american  \n",
      "\n",
      "[396 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Isolate potential matches with row sum >=3\n",
    "matches = potential_matches[potential_matches.sum(axis=1) >= 3]\n",
    "\n",
    "# Get values of second column index of matches\n",
    "matching_indices = matches.index.get_level_values(1)\n",
    "\n",
    "# Subset restaurants_new based on non-duplicate values\n",
    "non_dup = restaurants_new[~restaurants_new.index.isin(matching_indices)]\n",
    "\n",
    "# Append non_dup to restaurants\n",
    "full_restaurants = restaurants.append(non_dup)\n",
    "print(full_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84dfb38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
